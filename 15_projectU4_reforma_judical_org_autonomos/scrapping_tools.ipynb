{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipelines utilizados para obtener la información\n",
    "\n",
    "## 1. PIPELINE 1: Contenido de videos de YouTube\n",
    "\n",
    "Este pipeline se utiliza para extraer el contenido (Lo hablado) de los videos de YouTube que contienen información sobre los organismos autonomos y la reforma para la Ley del Poder Judicial. Es importante mencionar que este pipeline no recupera los titulos de los videos, la descripción de los videos o los comentarios de los videos. Unicamente tiene la función de extraer el contenido de videos de YouTube.\n",
    "\n",
    "### Proceso de ejecución del pipeline:\n",
    "\n",
    "1. Utilizando la herramiento de octoparse se puede efectuar web scraping para obtener la lista de videos de YouTube que contienen la información sobre los organismos autónomos y la reforma para la Ley del Poder Judicial. Un ejemplo de uso es que al incluir la palabra clave \"organismos autónomos\". Octoparse despues de un proceso de **casi 7 minutos**, logro recopilar 219 videos de youtube que hablan del tema. \n",
    "\n",
    "### Resumen del pipeline:\n",
    "1. Obtener listado de videos con **octoparse**.\n",
    "2. Quedarme unicamente con las urls y guardarlas en un csv de una unica columna.\n",
    "3. Descargar audio de videos de youtube utlizando **yp_dlp** y la **lista de urls**\n",
    "4. Obtener el corpus de cada uno de los audios utilizando **speech_recognition**\n",
    "5. Unir corpus en un solo archivo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "THE BELOW TOOL CAN BE USED TO DOWNLOAD AUDIO FROM YOUTUBE VIDEOS.\n",
    "- This tool use yt_dlp library to download audio from YouTube videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yt_dlp\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import csv\n",
    "import re\n",
    "import unicodedata\n",
    "\n",
    "def normalize_title(title: str) -> str:\n",
    "    \"\"\"\n",
    "    Normalizes a title following specified rules:\n",
    "    1. Converts to lowercase\n",
    "    2. Replaces spaces with underscores\n",
    "    3. Removes accents\n",
    "    4. Removes non-allowed characters (only allows letters, numbers and underscores)\n",
    "    \n",
    "    Args:\n",
    "        title (str): Original title to normalize\n",
    "        \n",
    "    Returns:\n",
    "        str: Normalized title\n",
    "    \"\"\"\n",
    "    # Convert to lowercase and Replace spaces with underscores\n",
    "    title = title.lower()\n",
    "    title = title.replace(' ', '_')\n",
    "    \n",
    "    # Remove accents\n",
    "    title = ''.join(\n",
    "        c for c in unicodedata.normalize('NFKD', title)\n",
    "        if not unicodedata.combining(c)\n",
    "    )\n",
    "    \n",
    "    # Remove non-allowed characters (only keeps letters, numbers and underscores)\n",
    "    title = re.sub(r'[^a-z0-9_]', '', title)\n",
    "    \n",
    "    # Remove multiple consecutive underscores and Remove underscores at the beginning and end\n",
    "    title = re.sub(r'_+', '_', title)\n",
    "    \n",
    "    title = title.strip('_')\n",
    "    \n",
    "    return title\n",
    "\n",
    "class BatchAudioDownloader:\n",
    "    def __init__(self):\n",
    "        self.success_count = 0\n",
    "        self.failed_count = 0\n",
    "        self.failed_urls = []\n",
    "\n",
    "    def download_audio(self, url: str, output_path: str) -> dict:\n",
    "        \"\"\"\n",
    "        Descarga el audio de un video de YouTube\n",
    "        \n",
    "        Args:\n",
    "            url (str): URL del video de YouTube\n",
    "            output_path (str): Ruta donde se guardará el audio\n",
    "            \n",
    "        Returns:\n",
    "            dict: Resultado de la descarga con status y mensaje\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Crear el directorio de salida si no existe\n",
    "            output_dir = Path(output_path)\n",
    "            output_dir.mkdir(parents=True, exist_ok=True)\n",
    "            \n",
    "            # Configuración para la descarga\n",
    "            ydl_opts = {\n",
    "                'format': 'bestaudio/best',\n",
    "                'postprocessors': [{\n",
    "                    'key': 'FFmpegExtractAudio',\n",
    "                    'preferredcodec': 'mp3',\n",
    "                    'preferredquality': '192',\n",
    "                }],\n",
    "                'outtmpl': str(output_dir / '%(title)s.%(ext)s'),\n",
    "                'quiet': False,\n",
    "                'no_warnings': True\n",
    "            }\n",
    "            \n",
    "            # Realizar la descarga\n",
    "            with yt_dlp.YoutubeDL(ydl_opts) as ydl:\n",
    "                # Obtener información del video primero\n",
    "                info = ydl.extract_info(url, download=False)\n",
    "                video_title = info.get('title', 'Unknown Title')\n",
    "                \n",
    "                # Normalizar el título\n",
    "                normalized_title = normalize_title(video_title)\n",
    "                \n",
    "                # Actualizar la configuración con el nuevo título normalizado\n",
    "                ydl_opts['outtmpl'] = str(output_dir / f'{normalized_title}.%(ext)s')\n",
    "                \n",
    "                print(f\"\\nDescargando: {video_title}\")\n",
    "                print(f\"Nombre del archivo: {normalized_title}.mp3\")\n",
    "                \n",
    "                # Crear nueva instancia con la configuración actualizada\n",
    "                with yt_dlp.YoutubeDL(ydl_opts) as ydl_download:\n",
    "                    ydl_download.download([url])\n",
    "                \n",
    "                return {\n",
    "                    'status': 'success',\n",
    "                    'message': f'Audio descargado exitosamente: {normalized_title}',\n",
    "                    'title': normalized_title,\n",
    "                    'url': url,\n",
    "                    'output_path': str(output_dir)\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'status': 'error',\n",
    "                'message': f'Error durante la descarga: {str(e)}',\n",
    "                'url': url\n",
    "            }\n",
    "\n",
    "    def process_csv(self, csv_path: str, output_path: str):\n",
    "        \"\"\"\n",
    "        Procesa un archivo CSV con URLs de YouTube y descarga los audios\n",
    "        \n",
    "        Args:\n",
    "            csv_path (str): Ruta al archivo CSV\n",
    "            output_path (str): Ruta donde se guardarán los audios\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Leer el CSV sin encabezados\n",
    "            urls = pd.read_csv(csv_path, header=None)[0].tolist()\n",
    "            total_urls = len(urls)\n",
    "            \n",
    "            print(f\"\\nIniciando proceso de descarga de {total_urls} videos...\")\n",
    "            \n",
    "            # Crear archivo de log\n",
    "            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "            log_file = Path(output_path) / f'download_log_{timestamp}.csv'\n",
    "            \n",
    "            with open(log_file, 'w', newline='', encoding='utf-8') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['URL', 'Status', 'Title', 'Error'])\n",
    "                \n",
    "                # Procesar cada URL\n",
    "                for index, url in enumerate(urls, 1):\n",
    "                    print(f\"\\nProcesando {index}/{total_urls}: {url}\")\n",
    "                    \n",
    "                    # Intentar descargar\n",
    "                    result = self.download_audio(url, output_path)\n",
    "                    \n",
    "                    # Actualizar contadores y log\n",
    "                    if result['status'] == 'success':\n",
    "                        self.success_count += 1\n",
    "                        writer.writerow([url, 'Success', result['title'], ''])\n",
    "                    else:\n",
    "                        self.failed_count += 1\n",
    "                        self.failed_urls.append(url)\n",
    "                        writer.writerow([url, 'Failed', '', result['message']])\n",
    "                    \n",
    "                    # Pequeña pausa entre descargas\n",
    "                    time.sleep(1)\n",
    "            \n",
    "            return {\n",
    "                'total': total_urls,\n",
    "                'success': self.success_count,\n",
    "                'failed': self.failed_count,\n",
    "                'log_file': str(log_file)\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error al procesar el CSV: {str(e)}\")\n",
    "            return None\n",
    "\n",
    "def main():\n",
    "    # Rutas de entrada y salida\n",
    "    csv_path = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/data_scraped/youtube_URLs/urls_reforma_al_poder_judicial_v01.csv\"\n",
    "    output_path = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/data_scraped/youtube_audio_poder_judicial_v01/\"\n",
    "    \n",
    "    # Crear instancia del descargador y procesar el CSV\n",
    "    downloader = BatchAudioDownloader()\n",
    "    results = downloader.process_csv(csv_path, output_path)\n",
    "    \n",
    "    # Mostrar resumen\n",
    "    if results:\n",
    "        print(\"\\n=== Resumen de Descargas ===\")\n",
    "        print(f\"Total de URLs procesadas: {results['total']}\")\n",
    "        print(f\"Descargas exitosas: {results['success']}\")\n",
    "        print(f\"Descargas fallidas: {results['failed']}\")\n",
    "        print(f\"Archivo de log: {results['log_file']}\")\n",
    "        \n",
    "        if downloader.failed_urls:\n",
    "            print(\"\\nURLs que fallaron:\")\n",
    "            for url in downloader.failed_urls:\n",
    "                print(f\"- {url}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "THE BELOW TOOL CAN BE USED TO GET AUDIO TEXT FROM AUDIO FILES.\n",
    "THIS TOOL USE:\n",
    "- SpeechRecognition library for Python to recognize speech.\n",
    "- Pydub library for Python to manipulate audio files.\n",
    "\n",
    "FOR GET TEXT FORM LARGE AUDIO FILES, THIS TOOL CAN BE USED TO SEGMENT THE FILES TO SMALLER SEGMENTS (Specificly 60sgs by segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import speech_recognition as sr\n",
    "from pydub import AudioSegment\n",
    "import threading\n",
    "from queue import Queue\n",
    "from typing import List\n",
    "\n",
    "class AudioTranscriber:\n",
    "    def __init__(self, input_folder: str, output_folder: str, max_threads: int = 8, language: str = 'es-ES'):\n",
    "        self.input_folder = input_folder\n",
    "        self.output_folder = output_folder\n",
    "        self.max_threads = max_threads\n",
    "        self.language = language\n",
    "        self.audio_queue = Queue()\n",
    "        self.active_threads = []\n",
    "        self.thread_semaphore = threading.Semaphore(max_threads)\n",
    "        \n",
    "        # Crear carpeta de salida si no existe\n",
    "        if not os.path.exists(output_folder):\n",
    "            os.makedirs(output_folder)\n",
    "\n",
    "    def prepare_voice_file(self, path: str) -> str:\n",
    "        if os.path.splitext(path)[1] == '.wav':\n",
    "            return path\n",
    "        elif os.path.splitext(path)[1] in ('.mp3', '.m4a', '.ogg', '.flac'):\n",
    "            audio_file = AudioSegment.from_file(\n",
    "                path, format=os.path.splitext(path)[1][1:])\n",
    "            wav_file = os.path.splitext(path)[0] + '.wav'\n",
    "            audio_file.export(wav_file, format='wav')\n",
    "            return wav_file\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f'Unsupported audio format: {format(os.path.splitext(path)[1])}')\n",
    "\n",
    "    def segment_audio(self, audio_path: str, segment_length: int = 45000):\n",
    "        audio = AudioSegment.from_file(audio_path)\n",
    "        segments = []\n",
    "        for i in range(0, len(audio), segment_length):\n",
    "            segment = audio[i:i+segment_length]\n",
    "            segments.append(segment)\n",
    "        return segments\n",
    "\n",
    "    def transcribe_audio(self, audio_data, language) -> str:\n",
    "        print(f'[Thread-{threading.current_thread().name}] Transcribiendo segmento de audio...')\n",
    "        r = sr.Recognizer()\n",
    "        try:\n",
    "            text = r.recognize_google(audio_data, language=language)\n",
    "            return text\n",
    "        except sr.RequestError as e:\n",
    "            print(f\"No se pudieron obtener resultados del servicio de reconocimiento de voz de Google; {e}\")\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Google Speech Recognition no pudo entender el audio\")\n",
    "        except Exception as e:\n",
    "            print(f\"Ocurrió un error: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "    def write_transcription_to_file(self, text: str, input_file: str) -> None:\n",
    "        # Obtener el nombre base del archivo de audio\n",
    "        base_name = os.path.splitext(os.path.basename(input_file))[0]\n",
    "        output_file = os.path.join(self.output_folder, f\"{base_name}.txt\")\n",
    "        \n",
    "        print(f'[Thread-{threading.current_thread().name}] Escribiendo transcripción en {output_file}')\n",
    "        with open(output_file, 'w', encoding='utf-8') as f:\n",
    "            f.write(text)\n",
    "\n",
    "    def process_single_file(self, input_file: str) -> None:\n",
    "        try:\n",
    "            with self.thread_semaphore:\n",
    "                print(f'[Thread-{threading.current_thread().name}] Procesando: {input_file}')\n",
    "                \n",
    "                # Preparar el archivo\n",
    "                wav_file = self.prepare_voice_file(input_file)\n",
    "                segments = self.segment_audio(wav_file)\n",
    "                full_transcription = \"\"\n",
    "\n",
    "                # Procesar cada segmento\n",
    "                for i, segment in enumerate(segments):\n",
    "                    print(f'[Thread-{threading.current_thread().name}] Procesando segmento {i+1} de {len(segments)}...')\n",
    "                    segment_file = f\"temp_segment_{threading.current_thread().name}_{i}.wav\"\n",
    "                    segment.export(segment_file, format=\"wav\")\n",
    "\n",
    "                    with sr.AudioFile(segment_file) as source:\n",
    "                        audio_data = sr.Recognizer().record(source)\n",
    "                        text = self.transcribe_audio(audio_data, self.language)\n",
    "                        full_transcription += text + \" \"\n",
    "\n",
    "                    # Limpieza del archivo temporal\n",
    "                    if os.path.exists(segment_file):\n",
    "                        os.remove(segment_file)\n",
    "\n",
    "                # Guardar la transcripción\n",
    "                self.write_transcription_to_file(full_transcription.strip(), input_file)\n",
    "\n",
    "                # Limpieza del archivo WAV si fue convertido\n",
    "                if wav_file != input_file and os.path.exists(wav_file):\n",
    "                    os.remove(wav_file)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f'[Thread-{threading.current_thread().name}] Error procesando {input_file}: {str(e)}')\n",
    "\n",
    "    def get_audio_files(self) -> List[str]:\n",
    "        \"\"\"Obtiene la lista de archivos de audio soportados en la carpeta de entrada.\"\"\"\n",
    "        supported_formats = ('.wav', '.mp3', '.m4a', '.ogg', '.flac')\n",
    "        audio_files = []\n",
    "        \n",
    "        for file in os.listdir(self.input_folder):\n",
    "            if file.lower().endswith(supported_formats):\n",
    "                audio_files.append(os.path.join(self.input_folder, file))\n",
    "        \n",
    "        return audio_files\n",
    "\n",
    "    def process_all_files(self):\n",
    "        \"\"\"Procesa todos los archivos de audio en la carpeta de entrada usando hilos.\"\"\"\n",
    "        audio_files = self.get_audio_files()\n",
    "        \n",
    "        if not audio_files:\n",
    "            print(\"No se encontraron archivos de audio soportados en la carpeta especificada.\")\n",
    "            return\n",
    "\n",
    "        print(f\"Se encontraron {len(audio_files)} archivos para procesar.\")\n",
    "        \n",
    "        # Crear y empezar hilos para cada archivo\n",
    "        for audio_file in audio_files:\n",
    "            thread = threading.Thread(target=self.process_single_file, args=(audio_file,))\n",
    "            thread.start()\n",
    "            self.active_threads.append(thread)\n",
    "\n",
    "        # Esperar a que todos los hilos terminen\n",
    "        for thread in self.active_threads:\n",
    "            thread.join()\n",
    "\n",
    "        print(\"Procesamiento completado para todos los archivos.\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Ejemplo de uso\n",
    "    input_folder = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/data_scraped/youtube_audio_poder_judicial_v01/\"\n",
    "    output_folder = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/data_scraped/youtube_corpus_from_audio_poder_judicial_v01/\"\n",
    "    \n",
    "    transcriber = AudioTranscriber(\n",
    "        input_folder=input_folder,\n",
    "        output_folder=output_folder,\n",
    "        max_threads=8,\n",
    "        language='es-ES'\n",
    "    )\n",
    "    \n",
    "    transcriber.process_all_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "### The bellow tool has been created to joint eache one .txt audio file into one large .txt audio file.\n",
    "#### Main characteristics:\n",
    "1. Can use this tool to combine all .txt files (Not only audios) into one large .txt file.\n",
    "2. Recive a input folder path with all .txt files.\n",
    "3. Recive a output file path to save the combined.txt file.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proceso completado. Archivo combinado guardado en: C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/principales_analisis_en_pdf_sobre_ley_a_la_reforma_del_poder_judicial.txt\n",
      "Total de archivos procesados: 14\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "def replace_in_string(original_string, old_substring, new_substring):\n",
    "    return original_string.replace(old_substring, new_substring)\n",
    "\n",
    "def combine_txt_files(input_folder, output_file):\n",
    "\n",
    "    try:\n",
    "        # Verificar que el directorio existe\n",
    "        if not os.path.exists(input_folder):\n",
    "            raise FileNotFoundError(f\"El directorio {input_folder} no existe\")\n",
    "        \n",
    "        # Obtener lista de archivos .txt en el directorio\n",
    "        txt_files = list(Path(input_folder).glob(\"*.txt\"))\n",
    "        \n",
    "        if not txt_files:\n",
    "            raise ValueError(f\"No se encontraron archivos .txt en {input_folder}\")\n",
    "        \n",
    "        # Crear el archivo de salida\n",
    "        with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "            for txt_file in txt_files:\n",
    "                try:\n",
    "                    # Leer el contenido del archivo actual\n",
    "                    with open(txt_file, 'r', encoding='utf-8') as infile:\n",
    "                        content = infile.read().strip()\n",
    "                        \n",
    "                    # Formatear el contenido con los marcadores requeridos\n",
    "                    file_name = replace_in_string(txt_file.name, '.txt', '')\n",
    "                    file_name = replace_in_string(file_name, '_', ' ')\n",
    "                    \n",
    "                    formatted_content = (\n",
    "                        f'[Aquí inicia el analisis en formato pdf de \"{file_name}\"] '\n",
    "                        f\"{content} \"\n",
    "                        f'[Aquí termina el analisis en formato pdf de \"{file_name}\"] '\n",
    "                    )\n",
    "                    # formatted_content = (\n",
    "                    #     f\"{content} \"\n",
    "                    # )\n",
    "                    \n",
    "                    # Escribir en el archivo de salida\n",
    "                    outfile.write(formatted_content)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"Error procesando el archivo {txt_file}: {str(e)}\")\n",
    "                    continue\n",
    "        \n",
    "        print(f\"Proceso completado. Archivo combinado guardado en: {output_file}\")\n",
    "        print(f\"Total de archivos procesados: {len(txt_files)}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error general en el proceso: {str(e)}\")\n",
    "\n",
    "# Uso del script\n",
    "#input_folder = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/data_scraped/youtube_corpus_from_audio_organismos_autonomos_v01/\"\n",
    "input_folder = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/data_scraped/pdf_to_corpus_poder_judicial_v1/\"\n",
    "\n",
    "#output_file = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/organismos_autonomo_corpus_con_etiquetas.txt\"\n",
    "output_file = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/principales_analisis_en_pdf_sobre_ley_a_la_reforma_del_poder_judicial.txt\"\n",
    "\n",
    "combine_txt_files(input_folder, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below tool has been created to extract text form from a given PDF file.\n",
    "#### Main characteristics\n",
    "1. Can extract text from PDF files using PyPDF2\n",
    "2. Recive a folder path as input and outputs a folder with text files extracted from each PDF file\n",
    "3. The output text files have corpus format (All in one line)\n",
    "4. The name of the output text file is the same as the name of the input PDF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# Definición de directorios\n",
    "# input_folder = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/data_scraped/pdf_organismos_autonomos_v1/\"\n",
    "# output_folder = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/data_scraped/pdf_to_corpus_organismos_autonomos_v1/\"\n",
    "\n",
    "input_folder = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/data_scraped/pdf_poder_judicial_v1/\"\n",
    "output_folder = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/data_scraped/pdf_to_corpus_poder_judicial_v1/\"\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Limpia el texto y lo convierte a una sola línea\"\"\"\n",
    "    # Elimina caracteres especiales pero mantiene puntuación básica\n",
    "    text = re.sub(r'[^\\w\\s.,;:!?¿¡-]', ' ', text)\n",
    "    # Reemplaza múltiples espacios con uno solo\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "def process_pdfs():\n",
    "    \"\"\"Procesa todos los PDFs en el directorio de entrada\"\"\"\n",
    "    # Crea el directorio de salida si no existe\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Obtiene lista de PDFs\n",
    "    pdf_files = [f for f in os.listdir(input_folder) if f.lower().endswith('.pdf')]\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        try:\n",
    "            # Rutas completas de entrada y salida\n",
    "            pdf_path = os.path.join(input_folder, pdf_file)\n",
    "            output_path = os.path.join(output_folder, pdf_file.replace('.pdf', '.txt'))\n",
    "            \n",
    "            print(f\"Procesando: {pdf_file}\")\n",
    "            \n",
    "            # Lee el PDF\n",
    "            reader = PdfReader(pdf_path)\n",
    "            text = \"\"\n",
    "            \n",
    "            # Extrae texto de cada página\n",
    "            for page in reader.pages:\n",
    "                text += page.extract_text() + \" \"\n",
    "            \n",
    "            # Limpia el texto\n",
    "            cleaned_text = clean_text(text)\n",
    "            \n",
    "            # Guarda el corpus\n",
    "            with open(output_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(cleaned_text)\n",
    "                \n",
    "            print(f\"Corpus generado: {pdf_file.replace('.pdf', '.txt')}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {pdf_file}: {str(e)}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_pdfs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below tool have been created to separate big .txt files into smaller files.\n",
    "\n",
    "#### Main characteristics\n",
    "1. Recive path to a big .txt file\n",
    "2. Recive a list of a dynamic number of paths to save the splitted files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_text_file(input_file_path, output_paths):\n",
    "    \"\"\"\n",
    "    Divide un archivo de texto en 10 partes iguales.\n",
    "    \n",
    "    Args:\n",
    "        input_file_path (str): Ruta del archivo de texto a dividir\n",
    "        output_paths (list): Lista de 10 rutas donde guardar las partes\n",
    "    \"\"\"\n",
    "    # Lee todo el contenido del archivo\n",
    "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
    "        content = file.read()\n",
    "    \n",
    "    # Calcula el tamaño de cada parte\n",
    "    total_length = len(content)\n",
    "    part_size = total_length // 10\n",
    "    \n",
    "    # Divide y guarda cada parte\n",
    "    for i, output_path in enumerate(output_paths):\n",
    "        start = i * part_size\n",
    "        # Si es la última parte, toma hasta el final del texto\n",
    "        end = total_length if i == 9 else (i + 1) * part_size\n",
    "        \n",
    "        # Extrae la parte correspondiente\n",
    "        part_content = content[start:end]\n",
    "        \n",
    "        # Guarda la parte en su archivo correspondiente\n",
    "        with open(output_path, 'w', encoding='utf-8') as file:\n",
    "            file.write(part_content)\n",
    "        \n",
    "        print(f\"Parte {i+1} guardada en: {output_path}\")\n",
    "\n",
    "# Ejemplo de uso\n",
    "input_folder = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/data_scraped/pdf_poder_judicial_v1/\"\n",
    "\n",
    "input_file = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/sin_procesar/corpus_full (1).txt\"\n",
    "output_files = [\n",
    "    \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/sin_procesar/divicion_del_grande/youtube_comments_parte1.txt\",\n",
    "    \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/sin_procesar/divicion_del_grande/youtube_comments_parte2.txt\",\n",
    "    \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/sin_procesar/divicion_del_grande/youtube_comments_parte3.txt\",\n",
    "    \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/sin_procesar/divicion_del_grande/youtube_comments_parte4.txt\",\n",
    "    \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/sin_procesar/divicion_del_grande/youtube_comments_parte5.txt\",\n",
    "    \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/sin_procesar/divicion_del_grande/tweets_parte1.txt\",\n",
    "    \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/sin_procesar/divicion_del_grande/tweets_parte2.txt\",\n",
    "    \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/sin_procesar/divicion_del_grande/tweets_parte3.txt\",\n",
    "    \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/sin_procesar/divicion_del_grande/tweets_parte4.txt\",\n",
    "    \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/sin_procesar/divicion_del_grande/tweets_parte5.txt\"\n",
    "    \n",
    "]\n",
    "\n",
    "# Ejecuta la división\n",
    "split_text_file(input_file, output_files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The below tool has been created to clean duble blank spaces and retuer lines in a text file.\n",
    "\n",
    "#### Main characteristics\n",
    "1. Recive a path to a folder with text files\n",
    "2. Recive a output path to save the cleaned text files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Limpia el texto eliminando espacios múltiples y saltos de línea.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Texto a limpiar\n",
    "    Returns:\n",
    "        str: Texto limpio en una sola línea\n",
    "    \"\"\"\n",
    "    # Reemplaza saltos de línea por espacios\n",
    "    text = text.replace('\\n', ' ')\n",
    "    # Reemplaza múltiples espacios por uno solo\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    # Elimina espacios al inicio y final\n",
    "    return text.strip()\n",
    "\n",
    "def process_txt_files(input_folder, output_folder):\n",
    "    \"\"\"\n",
    "    Procesa todos los archivos .txt en el directorio de entrada.\n",
    "    \n",
    "    Args:\n",
    "        input_folder (str): Ruta del directorio con los archivos .txt\n",
    "        output_folder (str): Ruta donde guardar los archivos procesados\n",
    "    \"\"\"\n",
    "    # Crea el directorio de salida si no existe\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Obtiene lista de archivos .txt\n",
    "    txt_files = [f for f in os.listdir(input_folder) if f.lower().endswith('.txt')]\n",
    "    \n",
    "    print(f\"Encontrados {len(txt_files)} archivos .txt para procesar\")\n",
    "    \n",
    "    for txt_file in txt_files:\n",
    "        try:\n",
    "            # Define rutas de entrada y salida\n",
    "            input_path = os.path.join(input_folder, txt_file)\n",
    "            output_filename = txt_file[:-4] + '_cleaned.txt'  # Añade _cleaned antes de .txt\n",
    "            output_path = os.path.join(output_folder, output_filename)\n",
    "            \n",
    "            print(f\"Procesando: {txt_file}\")\n",
    "            \n",
    "            # Lee el archivo\n",
    "            with open(input_path, 'r', encoding='utf-8') as file:\n",
    "                text = file.read()\n",
    "            \n",
    "            # Limpia el texto\n",
    "            cleaned_text = clean_text(text)\n",
    "            \n",
    "            # Guarda el texto limpio\n",
    "            with open(output_path, 'w', encoding='utf-8') as file:\n",
    "                file.write(cleaned_text)\n",
    "                \n",
    "            print(f\"Guardado: {output_filename}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error procesando {txt_file}: {str(e)}\")\n",
    "    \n",
    "    print(\"\\nProceso completado!\")\n",
    "\n",
    "# Rutas de ejemplo (reemplazar con tus rutas reales)\n",
    "input_folder = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/sin_procesar/\"\n",
    "output_folder = \"C:/git/IAClass/15_projectU4_reforma_judical_org_autonomos/corpus/\"\n",
    "\n",
    "# Ejecuta el procesamiento\n",
    "process_txt_files(input_folder, output_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
